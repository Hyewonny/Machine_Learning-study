▶▶통계문제 (7문제)
1. 회귀분석이 성립하기 위한 5가지 가정
- 선형성 : 독립변수의 변화에 따라 종속변수도 일정크기로 변화
- 독립성 : 잔차와 독립변인의 값이 관련되어 있지 않음
- 등분산성 : 독립변인의 모든 값에 대해 오차들의 분산이 일정
- 비상관성 : 관측치들의 잔차끼리 상관이 없어야 함
- 정상성 : 잔차 항이 정규분포를 이루어야 함

2. 회귀분석의 체크포인트 요약 
- 모형이 통계적으로 유의미한가 ? 
 -> F 통계량으로 확인
- 회귀계수들이 유의미한가 ?
 -> 계수에 대한 p-value, t 통계량, 신뢰구간 확인
- 모형이 얼마나 설명력을 지니는가 ?
 -> R-squared, Adjusted R-squared 값 확인
- 데이터가 전제하고 있는 가정을 만족시키는가 ?
 -> 회귀진단

3.베르누이 분포
확률론과 통계학에서 매 시행마다 오직 두 가지의 가능한 결과만 일어난다고 할 때, 이러한 실험을 1회 시행하여 일어난 두 가지 결과에 의해 
그 값이 각각 0과 1로 결정되는 확률변수 X에 대한 분포

4.CrossValidation (CV)
교차검증이라는 뜻, 과최적화가 일어나면 트레이닝 데이터에 대해서는 예측이 잘 되지만 테스트 데이터에 대해서는 예측 성능이 급격히 떨어지는 현상이 발생한다.
따라서 모형의 최종 성능을 객관적으로 측정하려면 트레이닝에 사용되지 않은 새로운 데이터, 
즉 검증용 혹은 테스트용 데이터를 사용해서 예측한 결과를 기반으로 성능을 계산해야 한다는 의미.

5.A/B TEST
마케팅에서 두 가지 이상의 시안 중 최적안을 선정하기 위해 시험하는 방법
단순 아웃풋에 대한 평가 척도로 인과 관계를 설명해줄수는 없다.

6.MLE 최대우도(Maximum Likelihood Estimation)
최대가능도라고도하며, 어떤 확률변수에서 표집한 값들을 토대로 그 확률변수의 모수를 구하는 방법이다.
어떤 모수가 주어졌을 떄, 원하는 값들이 나올 가능도를 최대로 만드는 모수를 선택하는 방법이며, 점추정 방식에 속한다.

7.MAP 최대 사후 확률 (Maximum A Posteriori)
베이즈 통계학에서 사후 확률의 최빈값을 가리킨다. 
최대 사후 확률 모수는 모수의 사전 확률과 결합된 확률을 고려한다는 점이 MLE와 다르다.
(여기서 사전확률이란 특정 사상이 일어나기 전의 확률, 관측을 하기 전에 가지고 있는 선험적인 확률 분포를 의미함)
사전확률과 가능도가 주어졌을 떄, 관측자는 관측값을 얻은 다음 베이즈 정리에 의해 사후확률을 얻을 수 있다.


▶▶선형대수 문제 (5문제)
1.Eigenvalue λ를 구하는 방법 det(A-λI) =0, 행렬식 det()은 어떤 행렬의 역행렬 존재여부에 대한 판별값 역할을 한다. 
2. Transpose(전치행렬) -> 행과 열을 바꾸면 됨
3. 선형독립과 종속
4. 고유값과 고유벡터
5. 직교행렬과 대칭행렬


▶▶머신러닝 용어 (5문제)
SSE SSR SST
회귀 모형과 기존의 데이터를 설명할 떄 사용되는 개념

1. SST :  총 변동(Total SS: total sum of squares), 개별 y의 편차의 제곱이다. 
이는 y의 평균에서 개별 관측값들을 뺀 값들에 대한 제곱의 합이다.
2. SSE : 설명된 변동( Model SS : model sum of squares), 회귀식 추정 y의 편차제곱의 합이다.
이는 회귀 추정선에서 y의 평균을 뺀 값들에 대한 제곱의 합이다.  
3. SSR : 잔차의 제곱(Residual sum of squares), 설명 안된 변동에 대한 값이다.
개별 실제 데이터에서 예측 값을 뺀 제곱의 합이다.
관계식으로는, SST = SSR + SSE로 설명할 수 있다.

4. 탐욕적 알고리즘
탐욕적 기법
욕심쟁이 알고리즘이라고도 불림, 
미리 정한 기준에 따라서 매번 가장 좋아 보이는 답을 선택하는 알고리즘 동적 계획법과 마찬가지로 최적화 문제를 푸는데 사용
(강화학습에서 주로 사용)

5. 게으른 알고리즘
함수가 오직 지역적으로 근사하고 모든 계산이 분류될 때까지 연기되는 학습 
또는 게으른 학습의 일종이다. k-NN 알고리즘은 가장 간단한 기계 학습 알고리즘에 속한다.
학습이라는 것에 속할 수도 없이 단순 비교로 분류하기 때문임, 간단하다는 뜻이다.

▶▶데이터구조 (3문제)

#  아래의 예시와 같이, 
# 하나의 리스트에는 vector, data.frame, 또다른 list, matrix를 원소로 가질 수 있음
# 그러나 데이터 프레임과 벡터는 같은 type의 데이터만 담을 수 있다.
## [[1]]
## [1] 1 2 3 4
## 
## [[2]]
##   y x
## 1 1 m
## 2 2 m
## 3 3 f
## 
## [[3]]
## [[3]][[1]]
## [1] "Hello!"
##
## [[3]][[2]]
## [1] "Hi"

1) list_a의 [[2]]의 값중, y열의 1행에 접근하고자 한다면? A. list_a[[2]][1,1]

두번쨰) Matrix
## 1. 아래의 array함수를 사용하여 3차원의 dimension을 갖는 matrix를 생성한다.
## X = array(0, dim=c(1,2,3))

> X
, , 1

     [,1] [,2]
[1,]    0    0

, , 2

     [,1] [,2]
[1,]    0    0

, , 3

     [,1] [,2]
[1,]    0    0
↑ 우리는 알 수있다. array함수의 인자값인 dimension에서 앞의 2개의 value는 각각의 행렬의 갯수를 나타내고,
나머지 인자값은 , , 1, , 2, , 3 과 같은 구분자를 나타내는 것 뿐이다.
그렇다면 4차원, 5차원 형태의 matrix도 가능한가?? -> o.k 가능하다. 만들면 장떙

두번째 문제 ) Y = array(1, dim= c(3,2,1))일때, Y의 데이터 구조를 그리시오.
   


세번째) data.frame

## 1. 아래의 명령어를 실행하면, 
## df <- data.frame(y = c(1:3), x = c("m", "m", "f"))
##
## 2. 아래와 같이 출력된다.
## > df
##    y x
## 1 1 m
## 2 2 m
## 3 3 f

세번째 문제) df[1]과 df[[1]]의 차이는 무엇인가?
 A. df의 형식의 차이이다.

> df[1]의 출력은 아래와 같고, (데이터 프레임 형식을 유지)
##    y 
## 1 1 
## 2 2 
## 3 3 

> df[[1]]의 출력은 아래와 같다. (데이터 프레임을 벡터로 풀어버린다.)
[1] 1 2 3
