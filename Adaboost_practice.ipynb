{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMatrix, dimen, threshVal, threshIneq) :\n",
    "    retArray = ones((shape(dataMatrix)[0],1))\n",
    "    \n",
    "    if threshIneq == 'lt' :\n",
    "        retArray[dataMatrix[:, dimen] <= threshVal]  = -1.0\n",
    "    else :\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildStump(dataArr, classLabels,D) : \n",
    "    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n",
    "    m, n = shape(dataMatrix)\n",
    "    numSteps = 10.0 ; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n",
    "    minError = inf\n",
    "    for i in range(n) : \n",
    "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();\n",
    "        stepSize = (rangeMax - rangeMin)/numSteps\n",
    "        for j in range(-1, int(numSteps)+1) : \n",
    "            for inequal in ['lt','gt'] : \n",
    "                threshVal = (rangeMin+float(j)*stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)\n",
    "                errArr = mat(ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr\n",
    "                #print (\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" %(i, threshVal, inequal, weightedError))\n",
    "                #print(errArr)\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    #print(\"minError = \",minError)\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    #print(\"bestClasEst = \",bestClasEst)\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "                    #print(\"bestStump =\",bestStump)\n",
    "    return bestStump, minError, bestClasEst\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "def loadSimpData():\n",
    "    datMat = matrix([[ 1. , 2.1],\n",
    "                    [ 2. , 1.1],\n",
    "                    [ 1.3, 1. ],\n",
    "                    [ 1. , 1. ],\n",
    "                    [ 2. , 1. ]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat,classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datMat , classLabels = loadSimpData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = mat(ones((5,1))/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'ineq': 'lt', 'thresh': 1.3}, matrix([[0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildStump(datMat, classLabels, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr, classLabels, numIt=40):\n",
    "    #number of iteration; iteration을 반복함으로써 error를 0에 가깝게 수렴\n",
    "    weakClassArr = []\n",
    "    #built for decision stumps\n",
    "    m = shape(dataArr)[0]\n",
    "    #받을 데이터 array의 총 데이터의 갯수\n",
    "    D = mat(ones((m,1))/m)\n",
    "    #weight vector의 초기값 -- 모두 동일하게\n",
    "    #increasethe weight of misclassified data + decrease the weight of the properly classified data\n",
    "    # m으로 나눠주는 이유 ; D는 확률분포이기 때문에 D값들의 sum을 한 것이 1이 되어야함\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    # predict한 class matrix  * alpha\n",
    "    for i in range(numIt) :\n",
    "        bestStump, error, classEst = buildStump(dataArr, classLabels,D)\n",
    "        # error : the lowest error returned, classEst : estimated classes for iteration D\n",
    "        print (\"D:\",D.T)\n",
    "        #######  after each classifier is trained , the classifier's weight is calcuated \n",
    "       # based on its accuracy. More accurate classifiers are given more weight\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))\n",
    "        # alpha : 첫번째 iteration에서 나온 분류기의 output weight 계산하기 based on classifier's error rate\n",
    "        # error가 커지면 alpha값이 작게설정, max값은 error가 0일때 오류가 나는 것을 방지하기위해 0에 가까운 값설정\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)\n",
    "        #alpha값을 best stump 딕셔너리에 저장, weakClassArr에 append\n",
    "        print(\"weakClassArr\", weakClassArr)\n",
    "        print (\"classEst : \", classEst.T)\n",
    "        expon = multiply(-1*alpha*mat(classLabels).T, classEst)\n",
    "        D = multiply(D, exp(expon))\n",
    "        D = D/D.sum()\n",
    "        # weight vector 구하기;  모든 데이터(m개)에 대해서 D를 구함\n",
    "        # classEst(우리의 예측치) 가 실제 classlabel과 다르면 weight가 더 더해지는 방향. \n",
    "        aggClassEst += alpha*classEst\n",
    "        print(\"aggClassEst : \", aggClassEst.T)\n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T, ones((m,1)))\n",
    "        \n",
    "        errorRate = aggErrors.sum()/m\n",
    "        print(\"total error : \",errorRate, \"\\n\")\n",
    "        if errorRate == 0.0 : break\n",
    "            # error =0 이라면 exit loop\n",
    "    return weakClassArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[0.2 0.2 0.2 0.2 0.2]]\n",
      "weakClassArr [{'alpha': 0.6931471805599453, 'dim': 0, 'ineq': 'lt', 'thresh': 1.3}]\n",
      "classEst :  [[-1.  1. -1. -1.  1.]]\n",
      "aggClassEst :  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error :  0.2 \n",
      "\n",
      "D: [[0.5   0.125 0.125 0.125 0.125]]\n",
      "weakClassArr [{'alpha': 0.6931471805599453, 'dim': 0, 'ineq': 'lt', 'thresh': 1.3}, {'alpha': 0.9729550745276565, 'dim': 1, 'ineq': 'lt', 'thresh': 1.0}]\n",
      "classEst :  [[ 1.  1. -1. -1. -1.]]\n",
      "aggClassEst :  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error :  0.2 \n",
      "\n",
      "D: [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
      "weakClassArr [{'alpha': 0.6931471805599453, 'dim': 0, 'ineq': 'lt', 'thresh': 1.3}, {'alpha': 0.9729550745276565, 'dim': 1, 'ineq': 'lt', 'thresh': 1.0}, {'alpha': 0.8958797346140273, 'dim': 0, 'ineq': 'lt', 'thresh': 0.9}]\n",
      "classEst :  [[1. 1. 1. 1. 1.]]\n",
      "aggClassEst :  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error :  0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "weakClassArr = adaBoostTrainDS(datMat, classLabels, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
